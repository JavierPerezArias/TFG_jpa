{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efba0bf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ctcas: (343854, 85) (343889, 85)\n",
      "ISOF: 33.692408323287964\n",
      "Ctcas: (343854, 22) (343854, 85)\n",
      "RFE: 671.8800809383392\n",
      "Cross-validation scores: [0.99998546 0.99997092 1.         0.99998546 1.        ]\n",
      "Average cross-validation score: 0.9999883671896583\n",
      "Accuracy: 0.999985458987073\n",
      "Kappa: 0.9999548667691287\n",
      "F1: 0.9999908911215761\n",
      "RF: 227.03534865379333\n",
      "Cross-validation scores: [0.9629495  0.94595105 0.94529671 0.94592197 0.94571761]\n",
      "Average cross-validation score: 0.9491673691457428\n",
      "Accuracy: 0.9453839554463364\n",
      "Kappa: 0.8369950305194112\n",
      "F1: 0.9653230422660044\n",
      "L-SVC: 230.1864275932312\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "import pydot\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data_dir = \"./datos\"\n",
    "\n",
    "def get_data(data_dir: str) -> pd.DataFrame:\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for path in os.listdir(data_dir):\n",
    "        dir_content = os.path.join(data_dir, path)\n",
    "        if os.path.isfile(dir_content):\n",
    "            data = data.append(pd.read_csv(dir_content))\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_data(data: pd.DataFrame):\n",
    "    \n",
    "    subnet1 = \"192\\.168\\.8\\.\\d{1,3}\"\n",
    "    subnet2 = \"192\\.168\\.3\\.\\d{1,3}\"\n",
    "    subnet3 = \"200\\.175\\.2\\.\\d{1,3}\"\n",
    "    subnet4 = \"192\\.168\\.20\\.\\d{1,3}\"\n",
    "    subnet5 = \"172\\.17\\.\\d{1,3}\\.\\d{1,3}\"\n",
    "    \n",
    "    data[\"Label\"].replace({\"DDoS \": \"DDoS\"}, inplace=True)\n",
    "    data.drop(\"Flow ID\", inplace=True, axis=1)\n",
    "    \n",
    "    data[\"Src 192.168.8.0/24\"] = data[\"Src IP\"].str.match(subnet1)\n",
    "    data[\"Src 192.168.3.0/24\"] = data[\"Src IP\"].str.match(subnet2)\n",
    "    data[\"Src 200.175.2.0/24\"] = data[\"Src IP\"].str.match(subnet3)\n",
    "    data[\"Src 192.168.20.0/24\"] = data[\"Src IP\"].str.match(subnet4)\n",
    "    data[\"Src 172.17.0.0/16\"] = data[\"Src IP\"].str.match(subnet5)\n",
    "    data[\"Src exterior ip\"] = ~data[\"Src IP\"].str.match(\"(\" + subnet1 + \"|\" + subnet2 + \"|\" + subnet3 + \"|\" + subnet4 + \"|\" + subnet5 + \")\")\n",
    "    \n",
    "    data[\"Src 192.168.8.0/24\"] = data[\"Src 192.168.8.0/24\"].astype(int)\n",
    "    data[\"Src 192.168.3.0/24\"] = data[\"Src 192.168.3.0/24\"].astype(int)\n",
    "    data[\"Src 200.175.2.0/24\"] = data[\"Src 200.175.2.0/24\"].astype(int)\n",
    "    data[\"Src 192.168.20.0/24\"] = data[\"Src 192.168.20.0/24\"].astype(int)\n",
    "    data[\"Src 172.17.0.0/16\"] = data[\"Src 172.17.0.0/16\"].astype(int)\n",
    "    data[\"Src exterior ip\"] = data[\"Src exterior ip\"].astype(int)\n",
    "    \n",
    "    data[\"Dst 192.168.8.0/24\"] = data[\"Dst IP\"].str.match(subnet1)\n",
    "    data[\"Dst 192.168.3.0/24\"] = data[\"Dst IP\"].str.match(subnet2)\n",
    "    data[\"Dst 200.175.2.0/24\"] = data[\"Dst IP\"].str.match(subnet3)\n",
    "    data[\"Dst 192.168.20.0/24\"] = data[\"Dst IP\"].str.match(subnet4)\n",
    "    data[\"Dst 172.17.0.0/16\"] = data[\"Dst IP\"].str.match(subnet5)\n",
    "    data[\"Dst exterior ip\"] = ~data[\"Dst IP\"].str.match(\"(\" + subnet1 + \"|\" + subnet2 + \"|\" + subnet3 + \"|\" + subnet4 + \"|\" + subnet5 + \")\")\n",
    "    \n",
    "    data[\"Dst 192.168.8.0/24\"] = data[\"Dst 192.168.8.0/24\"].astype(int)\n",
    "    data[\"Dst 192.168.3.0/24\"] = data[\"Dst 192.168.3.0/24\"].astype(int)\n",
    "    data[\"Dst 200.175.2.0/24\"] = data[\"Dst 200.175.2.0/24\"].astype(int)\n",
    "    data[\"Dst 192.168.20.0/24\"] = data[\"Dst 192.168.20.0/24\"].astype(int)\n",
    "    data[\"Dst 172.17.0.0/16\"] = data[\"Dst 172.17.0.0/16\"].astype(int)\n",
    "    data[\"Dst exterior ip\"] = data[\"Dst exterior ip\"].astype(int)\n",
    "    \n",
    "    data[[\"Day\", \"Hour\"]] = data[\"Timestamp\"].str.split(\" \", 1, expand=True)\n",
    "    data[[\"Hour\",\"Minute\",\"PM\"]] = data[\"Hour\"].str.split(\":\", 2, expand=True)\n",
    "    data[[\"Day\",\"PM\"]] = data[\"Day\"].str.split(\"/\", 1, expand=True)\n",
    "    data[\"PM\"] = data[\"Timestamp\"].str.match(\".*PM$\")\n",
    "    \n",
    "    data[\"PM\"] = data[\"PM\"].astype(int)\n",
    "    data[\"PM\"] = 12 * data[\"PM\"]\n",
    "    data[\"Hour\"] = data[\"Hour\"].astype(int) + data[\"PM\"]\n",
    "    data[\"Minute\"] = data[\"Minute\"].astype(int)\n",
    "    data[\"Day\"] = data[\"Day\"].astype(int)\n",
    "    \n",
    "    data[\"Hour sin\"] = np.sin(data[\"Hour\"]*(2.*np.pi/24))\n",
    "    data[\"Hour cos\"] = np.cos(data[\"Hour\"]*(2.*np.pi/24))\n",
    "    data[\"Minute sin\"] = np.sin(data[\"Minute\"]*(2.*np.pi/60))\n",
    "    data[\"Minute cos\"] = np.cos(data[\"Minute\"]*(2.*np.pi/60))\n",
    "    data[\"Day sin\"] = np.sin((data[\"Day\"]-1)*(2.*np.pi/31))\n",
    "    data[\"Day cos\"] = np.cos((data[\"Day\"]-1)*(2.*np.pi/31))\n",
    "    \n",
    "    data[\"Attack\"] = ~data[\"Label\"].str.match(\"Normal\")\n",
    "    data[\"Attack\"] = data[\"Attack\"].astype(int)\n",
    "    \n",
    "    data.drop(\"Hour\", inplace=True, axis=1)\n",
    "    data.drop(\"Minute\", inplace=True, axis=1)\n",
    "    data.drop(\"Day\", inplace=True, axis=1)\n",
    "    data.drop(\"PM\", inplace=True, axis=1)\n",
    "    \n",
    "    data.drop(\"Src IP\", inplace=True, axis=1)\n",
    "    data.drop(\"Dst IP\", inplace=True, axis=1)\n",
    "    data.drop(\"Timestamp\", inplace=True, axis=1)\n",
    "    data.drop(\"Label\", inplace=True, axis=1)\n",
    "    \n",
    "    #columnas irrelevantes\n",
    "    data.drop(\"Fwd PSH Flags\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd URG Flags\", inplace=True, axis=1)\n",
    "    data.drop(\"CWE Flag Count\", inplace=True, axis=1)\n",
    "    data.drop(\"ECE Flag Cnt\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Byts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Pkts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Blk Rate Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Bwd Byts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Bwd Pkts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Bwd Blk Rate Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Init Fwd Win Byts\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Seg Size Min\", inplace=True, axis=1)\n",
    "    \n",
    "    data = shuffle(data)\n",
    "    data.reset_index(drop=True, inplace=True)    \n",
    "    \n",
    "    return data\n",
    "\n",
    "def graphs(data: pd.DataFrame):\n",
    "    \n",
    "    column = input(\"Inserta una columna valida: \")\n",
    "    width = 0.35\n",
    "    \n",
    "    if column not in data.columns:\n",
    "        raise Exception(\"Error.\\n\")\n",
    "    \n",
    "    attack = data[data[\"Attack\"] == 1].reset_index()\n",
    "    normal = data[data[\"Attack\"] == 0].reset_index()\n",
    "        \n",
    "    plt.scatter(attack.index, attack[column], alpha=0.5)\n",
    "    plt.title(\"Gráfica base\")\n",
    "    plt.legend([\"Ataque\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(normal.index, normal[column], alpha=0.5)\n",
    "    plt.title(\"Gráfica base\")\n",
    "    plt.legend([\"Normal\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(normal.index, normal[column], alpha=0.5)\n",
    "    plt.scatter(attack.index, attack[column], alpha=0.5)\n",
    "    plt.title(\"Gráfica de contraste\")\n",
    "    plt.legend([\"Normal\",\"Ataque\"])\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(1 + width/2, normal[column].mean(), width, label=\"Normal\")\n",
    "    ax.bar(1 - width/2, attack[column].mean(), width, label=\"Ataque\")\n",
    "    ax.set_title(\"Gráfica de medias\")\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(1 + width/2, normal[column].max(), width, label=\"Normal\")\n",
    "    ax.bar(1 - width/2, attack[column].max(), width, label=\"Ataque\")\n",
    "    ax.set_title(\"Gráfica de máximos\")\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(1 + width/2, normal[column].min(), width, label=\"Normal\")\n",
    "    ax.bar(1 - width/2, attack[column].min(), width, label=\"Ataque\")\n",
    "    ax.set_title(\"Gráfica de mínimos\")\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def mapping(data: pd.DataFrame):\n",
    "    \n",
    "    # añadir a  heatmap para ver todos los nombres de columnas -> xticklabels=data.corr().columns, yticklabels=data.corr().columns \n",
    "    sns.heatmap(data.corr(), cmap=sns.diverging_palette(220, 10, as_cmap=True))\n",
    "    plt.title(\"Mapa de calor\")\n",
    "    plt.show()\n",
    "    \n",
    "    #cor_target = abs(data.corr()[\"Attack\"])\n",
    "    #relevant_features = cor_target[cor_target>0]\n",
    "    #print(relevant_features)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def isof(data: pd.DataFrame):\n",
    "    \n",
    "    y = np.array(data[\"Attack\"])\n",
    "    x = data.drop(\"Attack\", axis = 1)\n",
    "    \n",
    "    isof = IsolationForest(bootstrap=True, contamination=0.0001, n_jobs=-1)\n",
    "    y_isof = isof.fit_predict(x, y)\n",
    "    \n",
    "    x_isof = x.drop(x.index[np.asarray(np.where(y_isof == -1)).tolist()[0]])\n",
    "    y_isof = np.delete(y, np.asarray(np.where(y_isof == -1)).tolist()[0])\n",
    "    \n",
    "    print(\"Ctcas:\", x_isof.shape, x.shape)\n",
    "    \n",
    "    return x_isof,y_isof \n",
    "\n",
    "def rfe(x_isof: pd.DataFrame, y_isof: np.array):\n",
    "    \n",
    "    rfe = RFECV(DecisionTreeClassifier(), step=1, n_jobs=-1)\n",
    "    rfe.fit(x_isof, y_isof)\n",
    "    \n",
    "    x_isof_rfe = rfe.transform(x_isof)\n",
    "    \n",
    "    print(\"Ctcas:\", x_isof_rfe.shape, x_isof.shape)\n",
    "    \n",
    "    return x_isof_rfe,y_isof\n",
    "\n",
    "def pca(x_isof: pd.DataFrame, y_isof: np.array):\n",
    "    \n",
    "    pca = PCA(n_components=20)\n",
    "    pca.fit(x_isof, y_isof)\n",
    "    \n",
    "    x_isof_pca = pca.transform(x_isof)\n",
    "    \n",
    "    print(\"Ctcas:\", x_isof_pca.shape, x_isof.shape)\n",
    "    \n",
    "    return x_isof_pca,y_isof\n",
    "\n",
    "def rf(x_isof_rfe: pd.DataFrame, y_isof: np.array):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_isof_rfe, y_isof, test_size=0.2)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 100, max_features=\"sqrt\")\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    grid = {}\n",
    "    gscv = GridSearchCV(rf, grid, refit=True, verbose=4, n_jobs=-1)\n",
    "    \n",
    "    scores = cross_val_score(gscv, x_isof_rfe, y_isof, n_jobs=-1)\n",
    "    print(\"Cross-validation scores: {}\".format(scores))\n",
    "    print(\"Average cross-validation score: {}\".format(scores.mean()))\n",
    "    \n",
    "    predictions = rf.predict(x_test)\n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"Kappa:\", cohen_kappa_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"F1:\", f1_score(predictions.astype(np.int32), y_test))\n",
    "\n",
    "    return \n",
    "    \n",
    "def svm(x_isof_rfe: pd.DataFrame, y_isof: np.array):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_isof_rfe, y_isof, test_size=0.2)\n",
    "    \n",
    "    svm = LinearSVC(dual=False)\n",
    "    svm.fit(x_train, y_train)\n",
    "    \n",
    "    grid = {}\n",
    "    gscv = GridSearchCV(svm, grid, refit=True, verbose=4, n_jobs=-1)\n",
    "    \n",
    "    scores = cross_val_score(gscv, x_isof_rfe, y_isof, n_jobs=-1)\n",
    "    print(\"Cross-validation scores: {}\".format(scores))\n",
    "    print(\"Average cross-validation score: {}\".format(scores.mean()))\n",
    "    \n",
    "    predictions = svm.predict(x_test)\n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"Kappa:\", cohen_kappa_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"F1:\", f1_score(predictions.astype(np.int32), y_test))\n",
    "    \n",
    "    return \n",
    "    \n",
    "np.random.seed(1999)\n",
    "data = process_data(get_data(data_dir))\n",
    "#print(*data.columns, sep=\" - \")\n",
    "#graphs(data)\n",
    "#mapping(data)\n",
    "\n",
    "t0 = time.time()\n",
    "x, y = isof(data)\n",
    "t1 = time.time()\n",
    "print(f\"ISOF: {t1-t0}\")\n",
    "\n",
    "t0 = time.time()\n",
    "x, y = rfe(x, y)\n",
    "t1 = time.time()\n",
    "print(f\"RFE: {t1-t0}\")\n",
    "\n",
    "#t0 = time.time()\n",
    "#x, y = pca(x, y)\n",
    "#t1 = time.time()\n",
    "#print(f\"PCA: {t1-t0}\")\n",
    "\n",
    "t0 = time.time()\n",
    "rf(x_isof_rfe=x, y_isof=y)\n",
    "t1 = time.time()\n",
    "print(f\"RF: {t1-t0}\")\n",
    "\n",
    "t0 = time.time()\n",
    "svm(x_isof_rfe=x, y_isof=y)\n",
    "t1 = time.time()\n",
    "print(f\"L-SVC: {t1-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae63ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
