{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efba0bf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         1.         0.99997092 1.         0.99997092]\n",
      "Average cross-validation score: 0.9999883671050807\n",
      "Accuracy: 0.999985458987073\n",
      "Kappa: 0.9999546243666732\n",
      "RF: 856.0297689437866\n",
      "Ctcas: (343854, 21) (343854, 85)\n",
      "Cross-validation scores: [0.77637376 0.78073607 0.83174594 0.77512324 0.81705686]\n",
      "Average cross-validation score: 0.7962071717929249\n",
      "Accuracy: 0.8042634249901848\n",
      "Kappa: 0.4589747070463098\n",
      "SVM: 780.5863149166107\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pydot\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from graphviz import Source\n",
    "\n",
    "data_dir = \"./datos\"\n",
    "\n",
    "def get_data(data_dir: str) -> pd.DataFrame:\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for path in os.listdir(data_dir):\n",
    "        dir_content = os.path.join(data_dir, path)\n",
    "        if os.path.isfile(dir_content):\n",
    "            data = data.append(pd.read_csv(dir_content))\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_data(data: pd.DataFrame):\n",
    "    \n",
    "    subnet1 = \"192\\.168\\.8\\.\\d{1,3}\"\n",
    "    subnet2 = \"192\\.168\\.3\\.\\d{1,3}\"\n",
    "    subnet3 = \"200\\.175\\.2\\.\\d{1,3}\"\n",
    "    subnet4 = \"192\\.168\\.20\\.\\d{1,3}\"\n",
    "    subnet5 = \"172\\.17\\.\\d{1,3}\\.\\d{1,3}\"\n",
    "    \n",
    "    data[\"Label\"].replace({\"DDoS \": \"DDoS\"}, inplace=True)\n",
    "    data.drop(\"Flow ID\", inplace=True, axis=1)\n",
    "    \n",
    "    data[\"Src 192.168.8.0/24\"] = data[\"Src IP\"].str.match(subnet1)\n",
    "    data[\"Src 192.168.3.0/24\"] = data[\"Src IP\"].str.match(subnet2)\n",
    "    data[\"Src 200.175.2.0/24\"] = data[\"Src IP\"].str.match(subnet3)\n",
    "    data[\"Src 192.168.20.0/24\"] = data[\"Src IP\"].str.match(subnet4)\n",
    "    data[\"Src 172.17.0.0/16\"] = data[\"Src IP\"].str.match(subnet5)\n",
    "    data[\"Src exterior ip\"] = ~data[\"Src IP\"].str.match(\"(\" + subnet1 + \"|\" + subnet2 + \"|\" + subnet3 + \"|\" + subnet4 + \"|\" + subnet5 + \")\")\n",
    "    \n",
    "    data[\"Src 192.168.8.0/24\"] = data[\"Src 192.168.8.0/24\"].astype(int)\n",
    "    data[\"Src 192.168.3.0/24\"] = data[\"Src 192.168.3.0/24\"].astype(int)\n",
    "    data[\"Src 200.175.2.0/24\"] = data[\"Src 200.175.2.0/24\"].astype(int)\n",
    "    data[\"Src 192.168.20.0/24\"] = data[\"Src 192.168.20.0/24\"].astype(int)\n",
    "    data[\"Src 172.17.0.0/16\"] = data[\"Src 172.17.0.0/16\"].astype(int)\n",
    "    data[\"Src exterior ip\"] = data[\"Src exterior ip\"].astype(int)\n",
    "    \n",
    "    data[\"Dst 192.168.8.0/24\"] = data[\"Dst IP\"].str.match(subnet1)\n",
    "    data[\"Dst 192.168.3.0/24\"] = data[\"Dst IP\"].str.match(subnet2)\n",
    "    data[\"Dst 200.175.2.0/24\"] = data[\"Dst IP\"].str.match(subnet3)\n",
    "    data[\"Dst 192.168.20.0/24\"] = data[\"Dst IP\"].str.match(subnet4)\n",
    "    data[\"Dst 172.17.0.0/16\"] = data[\"Dst IP\"].str.match(subnet5)\n",
    "    data[\"Dst exterior ip\"] = ~data[\"Dst IP\"].str.match(\"(\" + subnet1 + \"|\" + subnet2 + \"|\" + subnet3 + \"|\" + subnet4 + \"|\" + subnet5 + \")\")\n",
    "    \n",
    "    data[\"Dst 192.168.8.0/24\"] = data[\"Dst 192.168.8.0/24\"].astype(int)\n",
    "    data[\"Dst 192.168.3.0/24\"] = data[\"Dst 192.168.3.0/24\"].astype(int)\n",
    "    data[\"Dst 200.175.2.0/24\"] = data[\"Dst 200.175.2.0/24\"].astype(int)\n",
    "    data[\"Dst 192.168.20.0/24\"] = data[\"Dst 192.168.20.0/24\"].astype(int)\n",
    "    data[\"Dst 172.17.0.0/16\"] = data[\"Dst 172.17.0.0/16\"].astype(int)\n",
    "    data[\"Dst exterior ip\"] = data[\"Dst exterior ip\"].astype(int)\n",
    "    \n",
    "    data[[\"Day\", \"Hour\"]] = data[\"Timestamp\"].str.split(\" \", 1, expand=True)\n",
    "    data[[\"Hour\",\"Minute\",\"PM\"]] = data[\"Hour\"].str.split(\":\", 2, expand=True)\n",
    "    data[[\"Day\",\"PM\"]] = data[\"Day\"].str.split(\"/\", 1, expand=True)\n",
    "    data[\"PM\"] = data[\"Timestamp\"].str.match(\".*PM$\")\n",
    "    \n",
    "    data[\"PM\"] = data[\"PM\"].astype(int)\n",
    "    data[\"PM\"] = 12 * data[\"PM\"]\n",
    "    data[\"Hour\"] = data[\"Hour\"].astype(int) + data[\"PM\"]\n",
    "    data[\"Minute\"] = data[\"Minute\"].astype(int)\n",
    "    data[\"Day\"] = data[\"Day\"].astype(int)\n",
    "    \n",
    "    data[\"Hour sin\"] = np.sin(data[\"Hour\"]*(2.*np.pi/24))\n",
    "    data[\"Hour cos\"] = np.cos(data[\"Hour\"]*(2.*np.pi/24))\n",
    "    data[\"Minute sin\"] = np.sin(data[\"Minute\"]*(2.*np.pi/60))\n",
    "    data[\"Minute cos\"] = np.cos(data[\"Minute\"]*(2.*np.pi/60))\n",
    "    data[\"Day sin\"] = np.sin((data[\"Day\"]-1)*(2.*np.pi/31))\n",
    "    data[\"Day cos\"] = np.cos((data[\"Day\"]-1)*(2.*np.pi/31))\n",
    "    \n",
    "    data[\"Attack\"] = ~data[\"Label\"].str.match(\"Normal\")\n",
    "    data[\"Attack\"] = data[\"Attack\"].astype(int)\n",
    "    \n",
    "    data.drop(\"Hour\", inplace=True, axis=1)\n",
    "    data.drop(\"Minute\", inplace=True, axis=1)\n",
    "    data.drop(\"Day\", inplace=True, axis=1)\n",
    "    data.drop(\"PM\", inplace=True, axis=1)\n",
    "    \n",
    "    data.drop(\"Src IP\", inplace=True, axis=1)\n",
    "    data.drop(\"Dst IP\", inplace=True, axis=1)\n",
    "    data.drop(\"Timestamp\", inplace=True, axis=1)\n",
    "    data.drop(\"Label\", inplace=True, axis=1)\n",
    "    \n",
    "    #columnas irrelevantes\n",
    "    data.drop(\"Fwd PSH Flags\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd URG Flags\", inplace=True, axis=1)\n",
    "    data.drop(\"CWE Flag Count\", inplace=True, axis=1)\n",
    "    data.drop(\"ECE Flag Cnt\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Byts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Pkts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Blk Rate Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Bwd Byts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Bwd Pkts/b Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Bwd Blk Rate Avg\", inplace=True, axis=1)\n",
    "    data.drop(\"Init Fwd Win Byts\", inplace=True, axis=1)\n",
    "    data.drop(\"Fwd Seg Size Min\", inplace=True, axis=1)\n",
    "    \n",
    "    data = shuffle(data)\n",
    "    data.reset_index(drop=True, inplace=True)    \n",
    "    \n",
    "    return data\n",
    "\n",
    "def graphs(data: pd.DataFrame):\n",
    "    \n",
    "    column = input(\"Inserta una columna valida: \")\n",
    "    width = 0.35\n",
    "    \n",
    "    if column not in data.columns:\n",
    "        raise Exception(\"Error.\\n\")\n",
    "    \n",
    "    attack = data[data[\"Attack\"] == 1].reset_index()\n",
    "    normal = data[data[\"Attack\"] == 0].reset_index()\n",
    "        \n",
    "    plt.scatter(attack.index, attack[column], alpha=0.5)\n",
    "    plt.title(\"Gráfica base\")\n",
    "    plt.legend([\"Ataque\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(normal.index, normal[column], alpha=0.5)\n",
    "    plt.title(\"Gráfica base\")\n",
    "    plt.legend([\"Normal\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(normal.index, normal[column], alpha=0.5)\n",
    "    plt.scatter(attack.index, attack[column], alpha=0.5)\n",
    "    plt.title(\"Gráfica de contraste\")\n",
    "    plt.legend([\"Normal\",\"Ataque\"])\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(1 + width/2, normal[column].mean(), width, label=\"Normal\")\n",
    "    ax.bar(1 - width/2, attack[column].mean(), width, label=\"Ataque\")\n",
    "    ax.set_title(\"Gráfica de medias\")\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(1 + width/2, normal[column].max(), width, label=\"Normal\")\n",
    "    ax.bar(1 - width/2, attack[column].max(), width, label=\"Ataque\")\n",
    "    ax.set_title(\"Gráfica de máximos\")\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(1 + width/2, normal[column].min(), width, label=\"Normal\")\n",
    "    ax.bar(1 - width/2, attack[column].min(), width, label=\"Ataque\")\n",
    "    ax.set_title(\"Gráfica de mínimos\")\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def mapping(data: pd.DataFrame):\n",
    "    \n",
    "    # añadir a  heatmap para ver todos los nombres de columnas -> xticklabels=data.corr().columns, yticklabels=data.corr().columns \n",
    "    sns.heatmap(data.corr(), cmap=sns.diverging_palette(220, 10, as_cmap=True))\n",
    "    plt.title(\"Mapa de calor\")\n",
    "    plt.show()\n",
    "    \n",
    "    #cor_target = abs(data.corr()[\"Attack\"])\n",
    "    #relevant_features = cor_target[cor_target>0]\n",
    "    #print(relevant_features)\n",
    "    \n",
    "    return\n",
    "\n",
    "def random_forest(data: pd.DataFrame):\n",
    "    \n",
    "    labels = np.array(data[\"Attack\"])\n",
    "    features = data.drop(\"Attack\", axis = 1)\n",
    "    feature_list = list(features.columns)\n",
    "    features = np.array(features)\n",
    "    \n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
    "    print(train_features.shape, train_labels.shape, test_features.shape, test_labels.shape)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 100, max_features=\"sqrt\", random_state = 42)\n",
    "    rf.fit(train_features, train_labels);\n",
    "    \n",
    "    predictions = rf.predict(test_features)\n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), test_labels))\n",
    "    \n",
    "    '''importances = list(rf.feature_importances_)# List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]# Sort the feature importances by most important first\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)# Print out the feature and importances \n",
    "    [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];'''\n",
    "    \n",
    "    '''rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "    rf_small.fit(train_features, train_labels)# Extract the small tree\n",
    "    tree_small = rf_small.estimators_[5]# Save the tree as a png image\n",
    "    export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "    (graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "    graph.write_png('small_tree.png')'''\n",
    "    \n",
    "    graph = Source(export_graphviz(rf.estimators_[5], out_file=None, feature_names=feature_list))\n",
    "    graph.format = 'png'\n",
    "    graph.render('dt0', view=False);\n",
    "    \n",
    "    print(\"Kappa:\", str(cohen_kappa_score(predictions.astype(np.int32), test_labels)))\n",
    "\n",
    "    return \n",
    "    \n",
    "def random_forest_isof(data: pd.DataFrame):\n",
    "    \n",
    "    y = np.array(data[\"Attack\"])\n",
    "    X = data.drop(\"Attack\", axis = 1)\n",
    "    \n",
    "    iforest = IsolationForest(bootstrap=True,\n",
    "                          contamination=0.0001, \n",
    "                          max_features=10, \n",
    "                          max_samples=10, \n",
    "                          n_estimators=100, \n",
    "                          n_jobs=-1,\n",
    "                         random_state=1)\n",
    "    y_pred = iforest.fit_predict(X)\n",
    "    \n",
    "    X.drop(X.index[np.asarray(np.where(y_pred != -1)).tolist()[0]]).to_csv(\"x.csv\")\n",
    "    np.savetxt(\"y.txt\", np.delete(y, np.asarray(np.where(y_pred != -1)).tolist()[0]))\n",
    "    \n",
    "    X_isof = X.drop(X.index[np.asarray(np.where(y_pred == -1)).tolist()[0]])\n",
    "    y_isof = np.delete(y, np.asarray(np.where(y_pred == -1)).tolist()[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_isof, y_isof, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 100, max_features=\"sqrt\", random_state = 42)\n",
    "    rfe = RFECV(rf, cv=5)\n",
    "    rfe.fit(X_train, y_train);\n",
    "    \n",
    "    predictions = rfe.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"Kappa:\", str(cohen_kappa_score(predictions.astype(np.int32), y_test)))\n",
    "    \n",
    "    graph = Source(export_graphviz(rf.estimators_[0], out_file=None, feature_names=list(X.columns)))\n",
    "    graph.format = 'png'\n",
    "    graph.render('dt1', view=False);\n",
    "    \n",
    "    return\n",
    "\n",
    "def linear_svm_isof(data: pd.DataFrame):\n",
    "    \n",
    "    y = np.array(data[\"Attack\"])\n",
    "    X = data.drop(\"Attack\", axis = 1)\n",
    "    \n",
    "    iforest = IsolationForest(bootstrap=True,\n",
    "                          contamination=0.0001, \n",
    "                          max_features=10, \n",
    "                          max_samples=10, \n",
    "                          n_estimators=100, \n",
    "                          n_jobs=-1,\n",
    "                         random_state=1)\n",
    "    y_pred = iforest.fit_predict(X)\n",
    "    \n",
    "    X_isof = X.drop(X.index[np.asarray(np.where(y_pred == -1)).tolist()[0]])\n",
    "    y_isof = np.delete(y, np.asarray(np.where(y_pred == -1)).tolist()[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_isof, y_isof, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    lsvm = LinearSVC(random_state=42)\n",
    "    #lsvm.n_iter_ = 20\n",
    "    lsvm.fit(X_train, y_train);\n",
    "    \n",
    "    predictions = lsvm.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"Kappa:\", str(cohen_kappa_score(predictions.astype(np.int32), y_test)))\n",
    "    \n",
    "    return\n",
    "\n",
    "def rf(data: pd.DataFrame):\n",
    "    \n",
    "    \n",
    "    y = np.array(data[\"Attack\"])\n",
    "    X = data.drop(\"Attack\", axis = 1)\n",
    "    \n",
    "    #isof\n",
    "    isof = IsolationForest(bootstrap=True, contamination=0.0001, n_jobs=-1)\n",
    "    y_isof = isof.fit_predict(X, y)\n",
    "    \n",
    "    X_isof = X.drop(X.index[np.asarray(np.where(y_isof == -1)).tolist()[0]])\n",
    "    y_isof = np.delete(y, np.asarray(np.where(y_isof == -1)).tolist()[0])\n",
    "    #end isof\n",
    "    \n",
    "    #rfe\n",
    "    rfe = RFECV(DecisionTreeClassifier(), n_jobs=-1)\n",
    "    rfe.fit(X_isof, y_isof)\n",
    "    \n",
    "    X_isof_rfe = rfe.transform(X_isof)\n",
    "    #end rfe\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_isof_rfe, y_isof, test_size=0.2)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 100, max_features=\"sqrt\")\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(rf, X_train, y_train, n_jobs=-1)\n",
    "    print(\"Cross-validation scores: {}\".format(scores))\n",
    "    print(\"Average cross-validation score: {}\".format(scores.mean()))\n",
    "    \n",
    "    predictions = rf.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"Kappa:\", cohen_kappa_score(predictions.astype(np.int32), y_test))\n",
    "\n",
    "    return \n",
    "    \n",
    "def svm(data: pd.DataFrame):\n",
    "    \n",
    "    \n",
    "    y = np.array(data[\"Attack\"])\n",
    "    X = data.drop(\"Attack\", axis = 1)\n",
    "    \n",
    "    #isof\n",
    "    isof = IsolationForest(bootstrap=True, contamination=0.0001, n_jobs=-1)\n",
    "    y_isof = isof.fit_predict(X, y)\n",
    "    \n",
    "    X_isof = X.drop(X.index[np.asarray(np.where(y_isof == -1)).tolist()[0]])\n",
    "    y_isof = np.delete(y, np.asarray(np.where(y_isof == -1)).tolist()[0])\n",
    "    #end isof\n",
    "    \n",
    "    #rfe\n",
    "    rfe = RFECV(DecisionTreeClassifier(), n_jobs=-1)\n",
    "    rfe.fit(X_isof, y_isof)\n",
    "    \n",
    "    X_isof_rfe = rfe.transform(X_isof)\n",
    "    print(\"Ctcas:\", X_isof_rfe.shape, X_isof.shape)\n",
    "    #end rfe\n",
    "    \n",
    "    #x val externa en vez de split, añadir f1 f1_score\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_isof_rfe, y_isof, test_size=0.2)\n",
    "    \n",
    "    svm = LinearSVC(dual=False)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(svm, X_train, y_train, n_jobs=-1)\n",
    "    print(\"Cross-validation scores: {}\".format(scores))\n",
    "    print(\"Average cross-validation score: {}\".format(scores.mean()))\n",
    "    \n",
    "    predictions = svm.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(predictions.astype(np.int32), y_test))\n",
    "    print(\"Kappa:\", cohen_kappa_score(predictions.astype(np.int32), y_test))\n",
    "\n",
    "    return \n",
    "    \n",
    "data = process_data(get_data(data_dir))\n",
    "#print(*data.columns, sep=\" - \")\n",
    "#graphs(data)\n",
    "#mapping(data)\n",
    "'''random_forest(data)\n",
    "random_forest_isof(data)\n",
    "linear_svm_isof(data)'''\n",
    "t0 = time.time()\n",
    "rf(data)\n",
    "t1 = time.time()\n",
    "print(f\"RF: {t1-t0}\")\n",
    "t1 = time.time()\n",
    "svm(data)\n",
    "t2 = time.time()\n",
    "print(f\"SVM: {t2-t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae63ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
